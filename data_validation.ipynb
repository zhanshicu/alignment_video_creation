{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation and Valid Files Generation\n",
    "\n",
    "This notebook:\n",
    "1. Starts from alignment_score.csv to get video IDs and scene numbers\n",
    "2. Validates that all required files exist for each scene\n",
    "3. Writes valid entries to a CSV file for efficient dataloader usage\n",
    "\n",
    "**Directory structure:**\n",
    "- Scene images: `data/video_scene_cuts/{video_id}/{video_id}-Scene-0xx-01.jpg`\n",
    "- Keyword masks: `keyword_masks/{video_id}/scene_{x}.png` (x = scene number)\n",
    "- Attention heatmaps: `attention_heatmap/{video_id}/{video_id}-Scene-0xx-01.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "print(\"Data validation notebook initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "ALIGNMENT_SCORE_FILE = 'data/alignment_score.csv'\n",
    "SCENE_IMAGES_DIR = 'data/video_scene_cuts'\n",
    "KEYWORD_MASKS_DIR = 'keyword_masks'\n",
    "ATTENTION_HEATMAPS_DIR = 'attention_heatmap'\n",
    "KEYWORDS_FILE = 'data/keywords.csv'\n",
    "\n",
    "# Output file\n",
    "OUTPUT_CSV = 'data/valid_scenes.csv'\n",
    "\n",
    "print(f\"Alignment scores: {ALIGNMENT_SCORE_FILE}\")\n",
    "print(f\"Scene images directory: {SCENE_IMAGES_DIR}\")\n",
    "print(f\"Keyword masks directory: {KEYWORD_MASKS_DIR}\")\n",
    "print(f\"Attention heatmaps directory: {ATTENTION_HEATMAPS_DIR}\")\n",
    "print(f\"Keywords file: {KEYWORDS_FILE}\")\n",
    "print(f\"Output CSV: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Alignment Scores and Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load alignment scores\n",
    "print(\"Loading alignment_score.csv...\")\n",
    "alignment_df = pd.read_csv(ALIGNMENT_SCORE_FILE)\n",
    "alignment_df.columns = alignment_df.columns.str.strip()\n",
    "\n",
    "print(f\"Total entries in alignment_score.csv: {len(alignment_df)}\")\n",
    "print(f\"Unique videos: {alignment_df['video id'].nunique()}\")\n",
    "print(f\"\\nColumns: {list(alignment_df.columns)}\")\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "print(alignment_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load keywords\n",
    "print(\"\\nLoading keywords.csv...\")\n",
    "keywords_df = pd.read_csv(KEYWORDS_FILE)\n",
    "keywords_df.columns = keywords_df.columns.str.strip()\n",
    "\n",
    "# Get video ID column\n",
    "if '_id' in keywords_df.columns:\n",
    "    video_id_col = '_id'\n",
    "elif 'video_id' in keywords_df.columns:\n",
    "    video_id_col = 'video_id'\n",
    "else:\n",
    "    raise ValueError(\"Could not find video ID column in keywords.csv\")\n",
    "\n",
    "# Get keyword column\n",
    "if 'keyword_list[0]' in keywords_df.columns:\n",
    "    keyword_col = 'keyword_list[0]'\n",
    "elif 'keyword' in keywords_df.columns:\n",
    "    keyword_col = 'keyword'\n",
    "else:\n",
    "    raise ValueError(\"Could not find keyword column in keywords.csv\")\n",
    "\n",
    "# Create keyword mapping\n",
    "keywords_map = dict(zip(\n",
    "    keywords_df[video_id_col].astype(str),\n",
    "    keywords_df[keyword_col]\n",
    "))\n",
    "\n",
    "# Filter out empty keywords\n",
    "keywords_map = {k: v for k, v in keywords_map.items() if pd.notna(v) and str(v).strip() != ''}\n",
    "\n",
    "print(f\"Loaded {len(keywords_map)} videos with valid keywords\")\n",
    "print(f\"Sample keywords: {list(keywords_map.items())[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Path Construction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_scene_image_path(video_id, scene_number):\n",
    "    \"\"\"\n",
    "    Construct path to scene image.\n",
    "    Format: data/video_scene_cuts/{video_id}/{video_id}-Scene-{scene_number:03d}-01.jpg\n",
    "    \"\"\"\n",
    "    filename = f\"{video_id}-Scene-{scene_number:03d}-01.jpg\"\n",
    "    path = os.path.join(SCENE_IMAGES_DIR, str(video_id), filename)\n",
    "    return path, filename\n",
    "\n",
    "def construct_keyword_mask_path(video_id, scene_number):\n",
    "    \"\"\"\n",
    "    Construct path to keyword mask.\n",
    "    Format: keyword_masks/{video_id}/scene_{scene_number}.png\n",
    "    \"\"\"\n",
    "    filename = f\"scene_{scene_number}.png\"\n",
    "    path = os.path.join(KEYWORD_MASKS_DIR, str(video_id), filename)\n",
    "    return path\n",
    "\n",
    "def construct_attention_heatmap_path(video_id, scene_number):\n",
    "    \"\"\"\n",
    "    Construct path to attention heatmap.\n",
    "    Format: attention_heatmap/{video_id}/{video_id}-Scene-{scene_number:03d}-01.jpg\n",
    "    \"\"\"\n",
    "    filename = f\"{video_id}-Scene-{scene_number:03d}-01.jpg\"\n",
    "    path = os.path.join(ATTENTION_HEATMAPS_DIR, str(video_id), filename)\n",
    "    return path\n",
    "\n",
    "# Test path construction\n",
    "test_video_id = \"123456\"\n",
    "test_scene_num = 1\n",
    "\n",
    "scene_path, scene_file = construct_scene_image_path(test_video_id, test_scene_num)\n",
    "mask_path = construct_keyword_mask_path(test_video_id, test_scene_num)\n",
    "heatmap_path = construct_attention_heatmap_path(test_video_id, test_scene_num)\n",
    "\n",
    "print(\"Test path construction:\")\n",
    "print(f\"  Scene image: {scene_path}\")\n",
    "print(f\"  Keyword mask: {mask_path}\")\n",
    "print(f\"  Attention heatmap: {heatmap_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Files for Each Scene\n",
    "\n",
    "Starting from alignment_score.csv entries, we check if all required files exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results list\n",
    "valid_scenes = []\n",
    "stats = {\n",
    "    'total_entries': len(alignment_df),\n",
    "    'missing_keyword': 0,\n",
    "    'missing_scene_image': 0,\n",
    "    'missing_keyword_mask': 0,\n",
    "    'missing_attention_heatmap': 0,\n",
    "    'valid_scenes': 0,\n",
    "}\n",
    "\n",
    "print(f\"\\nValidating {len(alignment_df)} scenes from alignment_score.csv...\\n\")\n",
    "\n",
    "# Iterate through alignment scores\n",
    "for idx, row in tqdm(alignment_df.iterrows(), total=len(alignment_df), desc=\"Validating scenes\"):\n",
    "    video_id = str(row['video id'])\n",
    "    scene_number = int(row['Scene Number'])\n",
    "    \n",
    "    # Check if video has keyword\n",
    "    if video_id not in keywords_map:\n",
    "        stats['missing_keyword'] += 1\n",
    "        continue\n",
    "    \n",
    "    keyword = keywords_map[video_id]\n",
    "    \n",
    "    # Construct paths\n",
    "    scene_image_path, filename = construct_scene_image_path(video_id, scene_number)\n",
    "    keyword_mask_path = construct_keyword_mask_path(video_id, scene_number)\n",
    "    attention_heatmap_path = construct_attention_heatmap_path(video_id, scene_number)\n",
    "    \n",
    "    # Check if scene image exists\n",
    "    if not os.path.exists(scene_image_path):\n",
    "        stats['missing_scene_image'] += 1\n",
    "        continue\n",
    "    \n",
    "    # Check if keyword mask exists\n",
    "    if not os.path.exists(keyword_mask_path):\n",
    "        stats['missing_keyword_mask'] += 1\n",
    "        continue\n",
    "    \n",
    "    # Check if attention heatmap exists\n",
    "    if not os.path.exists(attention_heatmap_path):\n",
    "        stats['missing_attention_heatmap'] += 1\n",
    "        continue\n",
    "    \n",
    "    # All checks passed - add to valid scenes\n",
    "    valid_scenes.append({\n",
    "        'video_id': video_id,\n",
    "        'scene_number': scene_number,\n",
    "        'keyword': keyword,\n",
    "        'scene_image_path': scene_image_path,\n",
    "        'keyword_mask_path': keyword_mask_path,\n",
    "        'attention_heatmap_path': attention_heatmap_path,\n",
    "        'filename': filename,\n",
    "    })\n",
    "    stats['valid_scenes'] += 1\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Validation Statistics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total entries in alignment_score.csv: {stats['total_entries']}\")\n",
    "print(f\"Missing keyword: {stats['missing_keyword']} scenes\")\n",
    "print(f\"Missing scene image: {stats['missing_scene_image']} scenes\")\n",
    "print(f\"Missing keyword mask: {stats['missing_keyword_mask']} scenes\")\n",
    "print(f\"Missing attention heatmap: {stats['missing_attention_heatmap']} scenes\")\n",
    "print(f\"\\n✅ VALID SCENES: {stats['valid_scenes']}\")\n",
    "print(f\"   ({stats['valid_scenes']/stats['total_entries']*100:.1f}% of total)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Valid Scenes to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(valid_scenes) > 0:\n",
    "    # Create DataFrame\n",
    "    valid_df = pd.DataFrame(valid_scenes)\n",
    "    \n",
    "    # Sort by video_id and scene_number\n",
    "    valid_df = valid_df.sort_values(['video_id', 'scene_number']).reset_index(drop=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)\n",
    "    valid_df.to_csv(OUTPUT_CSV, index=False)\n",
    "    \n",
    "    print(f\"\\n✅ Saved {len(valid_df)} valid scenes to: {OUTPUT_CSV}\")\n",
    "    print(f\"\\nColumns: {list(valid_df.columns)}\")\n",
    "    print(f\"\\nUnique videos: {valid_df['video_id'].nunique()}\")\n",
    "    \n",
    "    # Scenes per video statistics\n",
    "    scenes_per_video = valid_df.groupby('video_id').size()\n",
    "    print(f\"\\nScenes per video:\")\n",
    "    print(f\"  Min: {scenes_per_video.min()}\")\n",
    "    print(f\"  Max: {scenes_per_video.max()}\")\n",
    "    print(f\"  Mean: {scenes_per_video.mean():.1f}\")\n",
    "    print(f\"  Median: {scenes_per_video.median():.0f}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    print(valid_df.head())\n",
    "    \n",
    "    # Display sample paths\n",
    "    print(f\"\\nSample paths for first scene:\")\n",
    "    first_scene = valid_df.iloc[0]\n",
    "    print(f\"  Video ID: {first_scene['video_id']}\")\n",
    "    print(f\"  Scene number: {first_scene['scene_number']}\")\n",
    "    print(f\"  Keyword: {first_scene['keyword']}\")\n",
    "    print(f\"  Scene image: {first_scene['scene_image_path']}\")\n",
    "    print(f\"  Keyword mask: {first_scene['keyword_mask_path']}\")\n",
    "    print(f\"  Attention heatmap: {first_scene['attention_heatmap_path']}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"⚠️  WARNING: No valid scenes found!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nPlease check:\")\n",
    "    print(\"  1. Scene images exist in:\", SCENE_IMAGES_DIR)\n",
    "    print(\"     Format: {video_id}/{video_id}-Scene-{number:03d}-01.jpg\")\n",
    "    print(\"\\n  2. Keyword masks exist in:\", KEYWORD_MASKS_DIR)\n",
    "    print(\"     Format: {video_id}/scene_{number}.png\")\n",
    "    print(\"\\n  3. Attention heatmaps exist in:\", ATTENTION_HEATMAPS_DIR)\n",
    "    print(\"     Format: {video_id}/{video_id}-Scene-{number:03d}-01.jpg\")\n",
    "    print(\"\\n  4. Keywords.csv contains valid keywords for the videos\")\n",
    "    print(\"\\n  5. Video IDs and scene numbers in alignment_score.csv are correct\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has created a CSV file (`data/valid_scenes.csv`) containing all scenes that have:\n",
    "1. Entry in `alignment_score.csv`\n",
    "2. Scene image in `data/video_scene_cuts/`\n",
    "3. Keyword mask in `keyword_masks/`\n",
    "4. Attention heatmap in `attention_heatmap/`\n",
    "5. Valid keyword in `data/keywords.csv`\n",
    "\n",
    "The dataloader will now use this CSV file to load only valid scenes, avoiding repeated file existence checks.\n",
    "\n",
    "### Path Formats Verified\n",
    "\n",
    "- **Scene images**: `data/video_scene_cuts/{video_id}/{video_id}-Scene-{number:03d}-01.jpg`\n",
    "- **Keyword masks**: `keyword_masks/{video_id}/scene_{number}.png`\n",
    "- **Attention heatmaps**: `attention_heatmap/{video_id}/{video_id}-Scene-{number:03d}-01.jpg`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

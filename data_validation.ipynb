{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation and Valid Files Generation\n",
    "\n",
    "This notebook:\n",
    "1. Scans through scene images, keyword masks, and attention heatmaps\n",
    "2. Validates that all required files exist for each scene\n",
    "3. Writes valid entries to a CSV file for efficient dataloader usage\n",
    "\n",
    "**Directory structure:**\n",
    "- Scene images: `data/video_scene_cuts/[video_id]/[video_id]-Scene-0xx-01.jpg`\n",
    "- Keyword masks: `keyword_masks/[video_id]/[video_id]-Scene-0xx-01.png`\n",
    "- Attention heatmaps: `attention_heatmap/[video_id]/[video_id]-Scene-0xx-01.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "print(\"Data validation notebook initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "SCENE_IMAGES_DIR = 'data/video_scene_cuts'\n",
    "KEYWORD_MASKS_DIR = 'keyword_masks'\n",
    "ATTENTION_HEATMAPS_DIR = 'attention_heatmap'\n",
    "KEYWORDS_FILE = 'data/keywords.csv'\n",
    "\n",
    "# Output file\n",
    "OUTPUT_CSV = 'data/valid_scenes.csv'\n",
    "\n",
    "print(f\"Scene images directory: {SCENE_IMAGES_DIR}\")\n",
    "print(f\"Keyword masks directory: {KEYWORD_MASKS_DIR}\")\n",
    "print(f\"Attention heatmaps directory: {ATTENTION_HEATMAPS_DIR}\")\n",
    "print(f\"Keywords file: {KEYWORDS_FILE}\")\n",
    "print(f\"Output CSV: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load keywords\n",
    "keywords_df = pd.read_csv(KEYWORDS_FILE)\n",
    "keywords_df.columns = keywords_df.columns.str.strip()\n",
    "\n",
    "# Get video ID column\n",
    "if '_id' in keywords_df.columns:\n",
    "    video_id_col = '_id'\n",
    "elif 'video_id' in keywords_df.columns:\n",
    "    video_id_col = 'video_id'\n",
    "else:\n",
    "    raise ValueError(\"Could not find video ID column in keywords.csv\")\n",
    "\n",
    "# Get keyword column\n",
    "if 'keyword_list[0]' in keywords_df.columns:\n",
    "    keyword_col = 'keyword_list[0]'\n",
    "elif 'keyword' in keywords_df.columns:\n",
    "    keyword_col = 'keyword'\n",
    "else:\n",
    "    raise ValueError(\"Could not find keyword column in keywords.csv\")\n",
    "\n",
    "# Create keyword mapping\n",
    "keywords_map = dict(zip(\n",
    "    keywords_df[video_id_col].astype(str),\n",
    "    keywords_df[keyword_col]\n",
    "))\n",
    "\n",
    "# Filter out empty keywords\n",
    "keywords_map = {k: v for k, v in keywords_map.items() if pd.notna(v) and str(v).strip() != ''}\n",
    "\n",
    "print(f\"Loaded {len(keywords_map)} videos with valid keywords\")\n",
    "print(f\"Sample keywords: {list(keywords_map.items())[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Scene Filename\n",
    "\n",
    "Scene filenames follow the pattern: `[video_id]-Scene-0xx-01.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scene_filename(filename):\n",
    "    \"\"\"\n",
    "    Parse scene filename to extract video_id and scene_number.\n",
    "    \n",
    "    Expected format: [video_id]-Scene-0xx-01.jpg\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (video_id, scene_number) or (None, None) if parsing fails\n",
    "    \"\"\"\n",
    "    # Pattern: anything before '-Scene-', then digits, then '-01'\n",
    "    pattern = r'^(.+?)-Scene-(\\d+)-01\\.(jpg|png)$'\n",
    "    match = re.match(pattern, filename)\n",
    "    \n",
    "    if match:\n",
    "        video_id = match.group(1)\n",
    "        scene_number = int(match.group(2))\n",
    "        return video_id, scene_number\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Test parsing\n",
    "test_filename = \"123456-Scene-001-01.jpg\"\n",
    "vid, scene = parse_scene_filename(test_filename)\n",
    "print(f\"Test parsing: '{test_filename}' -> video_id='{vid}', scene={scene}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan and Validate Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file_exists(base_dir, video_id, filename):\n",
    "    \"\"\"Check if a file exists in the expected location.\"\"\"\n",
    "    path = os.path.join(base_dir, video_id, filename)\n",
    "    return os.path.exists(path), path\n",
    "\n",
    "# Initialize results list\n",
    "valid_scenes = []\n",
    "stats = {\n",
    "    'total_scene_files': 0,\n",
    "    'missing_keyword': 0,\n",
    "    'missing_keyword_mask': 0,\n",
    "    'missing_attention_heatmap': 0,\n",
    "    'valid_scenes': 0,\n",
    "}\n",
    "\n",
    "# Check if scene images directory exists\n",
    "if not os.path.exists(SCENE_IMAGES_DIR):\n",
    "    print(f\"ERROR: Scene images directory not found: {SCENE_IMAGES_DIR}\")\n",
    "else:\n",
    "    # Scan scene images directory\n",
    "    print(\"\\nScanning scene images directory...\")\n",
    "    video_dirs = [d for d in os.listdir(SCENE_IMAGES_DIR) \n",
    "                  if os.path.isdir(os.path.join(SCENE_IMAGES_DIR, d))]\n",
    "    \n",
    "    print(f\"Found {len(video_dirs)} video directories\")\n",
    "    \n",
    "    for video_id in tqdm(video_dirs, desc=\"Validating scenes\"):\n",
    "        # Check if video has keyword\n",
    "        if video_id not in keywords_map:\n",
    "            stats['missing_keyword'] += 1\n",
    "            continue\n",
    "        \n",
    "        keyword = keywords_map[video_id]\n",
    "        \n",
    "        # Get all scene files for this video\n",
    "        video_scene_dir = os.path.join(SCENE_IMAGES_DIR, video_id)\n",
    "        scene_files = [f for f in os.listdir(video_scene_dir) \n",
    "                      if f.endswith('.jpg') or f.endswith('.png')]\n",
    "        \n",
    "        for scene_file in scene_files:\n",
    "            stats['total_scene_files'] += 1\n",
    "            \n",
    "            # Parse filename\n",
    "            parsed_vid, scene_number = parse_scene_filename(scene_file)\n",
    "            if parsed_vid is None:\n",
    "                # Skip files that don't match expected pattern\n",
    "                continue\n",
    "            \n",
    "            # Update video_id to parsed value (in case directory name differs)\n",
    "            video_id_parsed = parsed_vid\n",
    "            \n",
    "            # Check for keyword mask (should have .png extension)\n",
    "            mask_filename = scene_file.replace('.jpg', '.png')\n",
    "            mask_exists, mask_path = check_file_exists(KEYWORD_MASKS_DIR, video_id, mask_filename)\n",
    "            \n",
    "            if not mask_exists:\n",
    "                stats['missing_keyword_mask'] += 1\n",
    "                continue\n",
    "            \n",
    "            # Check for attention heatmap (same filename as scene)\n",
    "            heatmap_exists, heatmap_path = check_file_exists(ATTENTION_HEATMAPS_DIR, video_id, scene_file)\n",
    "            \n",
    "            if not heatmap_exists:\n",
    "                stats['missing_attention_heatmap'] += 1\n",
    "                continue\n",
    "            \n",
    "            # All checks passed - add to valid scenes\n",
    "            valid_scenes.append({\n",
    "                'video_id': video_id_parsed,\n",
    "                'scene_number': scene_number,\n",
    "                'keyword': keyword,\n",
    "                'scene_image_path': os.path.join(SCENE_IMAGES_DIR, video_id, scene_file),\n",
    "                'keyword_mask_path': mask_path,\n",
    "                'attention_heatmap_path': heatmap_path,\n",
    "                'filename': scene_file,\n",
    "            })\n",
    "            stats['valid_scenes'] += 1\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Validation Statistics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total scene files found: {stats['total_scene_files']}\")\n",
    "print(f\"Missing keyword: {stats['missing_keyword']} videos\")\n",
    "print(f\"Missing keyword mask: {stats['missing_keyword_mask']} scenes\")\n",
    "print(f\"Missing attention heatmap: {stats['missing_attention_heatmap']} scenes\")\n",
    "print(f\"\\nVALID SCENES: {stats['valid_scenes']}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Valid Scenes to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(valid_scenes) > 0:\n",
    "    # Create DataFrame\n",
    "    valid_df = pd.DataFrame(valid_scenes)\n",
    "    \n",
    "    # Sort by video_id and scene_number\n",
    "    valid_df = valid_df.sort_values(['video_id', 'scene_number']).reset_index(drop=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)\n",
    "    valid_df.to_csv(OUTPUT_CSV, index=False)\n",
    "    \n",
    "    print(f\"\\n✓ Saved {len(valid_df)} valid scenes to: {OUTPUT_CSV}\")\n",
    "    print(f\"\\nColumns: {list(valid_df.columns)}\")\n",
    "    print(f\"\\nUnique videos: {valid_df['video_id'].nunique()}\")\n",
    "    print(f\"Scenes per video: {valid_df.groupby('video_id').size().describe()}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    print(valid_df.head())\n",
    "else:\n",
    "    print(\"\\n⚠ No valid scenes found. Please check:\")\n",
    "    print(\"  1. Scene images directory exists and contains video folders\")\n",
    "    print(\"  2. Keyword masks directory exists with matching files\")\n",
    "    print(\"  3. Attention heatmaps directory exists with matching files\")\n",
    "    print(\"  4. Keywords.csv contains valid keywords for the videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has created a CSV file (`data/valid_scenes.csv`) containing all scenes that have:\n",
    "1. Scene image in `data/video_scene_cuts/`\n",
    "2. Keyword mask in `keyword_masks/`\n",
    "3. Attention heatmap in `attention_heatmap/`\n",
    "4. Valid keyword in `data/keywords.csv`\n",
    "\n",
    "The dataloader will now use this CSV file to load only valid scenes, avoiding repeated file existence checks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
